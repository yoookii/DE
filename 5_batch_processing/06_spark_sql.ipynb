{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03742dcf-6741-46e2-a1a3-4ff88193e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d50a16-9670-42fe-ac64-5cbb5a008b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scala' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.jars.packages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcom.google.cloud.spark:spark-bigquery-with-dependencies_2.13:0.39.1\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.driver.extraClassPath\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/opt/homebrew/opt/scala@2.13/libexec/lib\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpark Version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, spark\u001b[38;5;241m.\u001b[39mversion)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScala Version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, spark\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39mgetConf()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.scala.version\u001b[39m\u001b[38;5;124m\"\u001b[39m), scala\u001b[38;5;241m.\u001b[39mversion)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scala' is not defined"
     ]
    }
   ],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#     .master(\"spark://Yokis-MacBook-Pro.local:7077\") \\\n",
    "#     .appName('test') \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('test') \\\n",
    "    .config('spark.jars.packages', 'com.google.cloud.spark:spark-bigquery-with-dependencies_2.13:0.39.1') \\\n",
    "    .config('spark.sql.execution.arrow.pyspark.enabled', 'true') \\\n",
    "    .config('spark.sql.catalogImplementation', 'hive') \\\n",
    "    .config('spark.executor.extraClassPath', '/opt/homebrew/opt/scala@2.13/libexec/lib') \\\n",
    "    .config('spark.driver.extraClassPath', '/opt/homebrew/opt/scala@2.13/libexec/lib') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Version:\", spark.version)\n",
    "print(\"Scala Version:\", spark.sparkContext.getConf().get(\"spark.scala.version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3e0fb8-439f-4c84-b490-4c6d45fcf916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.93:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://Yokis-MacBook-Pro.local:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1087de710>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82cdefa3-4237-4105-9aa3-63412db95270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'test'),\n",
       " ('spark.app.submitTime', '1720028102161'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.master', 'spark://Yokis-MacBook-Pro.local:7077')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "SparkConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e718ca35-c55c-4a46-8445-22bed17e883d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet('data/pq/green/*/*')\n",
    "df_yellow = spark.read.parquet('data/pq/yellow/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63eede74-6d8a-48d4-b5ed-50af333d165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = df_green \\\n",
    "    .withColumnRenamed('lpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('lpep_dropoff_datetime', 'dropoff_datetime')\n",
    "\n",
    "df_yellow = df_yellow \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ebd6ef-8499-42c3-8463-00940a23687e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DOLocationID',\n",
       " 'PULocationID',\n",
       " 'RatecodeID',\n",
       " 'VendorID',\n",
       " 'congestion_surcharge',\n",
       " 'dropoff_datetime',\n",
       " 'extra',\n",
       " 'fare_amount',\n",
       " 'improvement_surcharge',\n",
       " 'mta_tax',\n",
       " 'passenger_count',\n",
       " 'payment_type',\n",
       " 'pickup_datetime',\n",
       " 'store_and_fwd_flag',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'total_amount',\n",
       " 'trip_distance'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframes into one \n",
    "set(df_green.columns) & set(df_yellow.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf71507f-9d05-4f19-bbb7-150b46051711",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = []\n",
    "yellow_columns = set(df_yellow.columns)\n",
    "for col in df_green.columns: \n",
    "    if col in yellow_columns: \n",
    "        common_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f555f8-7943-45f3-ad2c-5e640d011a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2aad9ff-ccee-4818-9a5a-92577f470976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_sel = df_green \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn('service_type', F.lit('green'))\n",
    "\n",
    "df_yellow_sel = df_yellow \\\n",
    "    .select(common_columns) \\\n",
    "    .withColumn('service_type', F.lit('yellow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ee60da-ed64-4ed8-b9d4-b0f7a3faba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data = df_green_sel.unionAll(df_yellow_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9b08dc-f597-4900-932f-81c27dccd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_data.createOrReplaceTempView('trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3610d97f-eefe-4712-a7e5-40493f48623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    PULocationID AS revenue_zone,\n",
    "    date_trunc('month', pickup_datetime) AS revenue_month, \n",
    "    service_type, \n",
    "\n",
    "    -- Revenue calculation \n",
    "    SUM(fare_amount) AS revenue_monthly_fare,\n",
    "    SUM(extra) AS revenue_monthly_extra,\n",
    "    SUM(mta_tax) AS revenue_monthly_mta_tax,\n",
    "    SUM(tip_amount) AS revenue_monthly_tip_amount,\n",
    "    SUM(tolls_amount) AS revenue_monthly_tolls_amount,\n",
    "    SUM(improvement_surcharge) AS revenue_monthly_improvement_surcharge,\n",
    "    SUM(total_amount) AS revenue_monthly_total_amount,\n",
    "    SUM(congestion_surcharge) AS revenue_monthly_congestion_surcharge,\n",
    "\n",
    "    -- Additional calculations\n",
    "    AVG(passenger_count) AS avg_montly_passenger_count,\n",
    "    AVG(trip_distance) AS avg_montly_trip_distance\n",
    "FROM\n",
    "    trips_data\n",
    "GROUP BY\n",
    "    1, 2, 3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd68ff3c-fa65-40ff-a1b2-c0a56f41e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.write.parquet('data/report/revenue/', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e02f6f-3d53-4084-a50b-ed76075ed87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
